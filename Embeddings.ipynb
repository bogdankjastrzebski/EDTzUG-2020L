{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.data import Sentence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.distance import PairwiseDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polish word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl = WordEmbeddings('pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordEmbeddings('pl')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl = WordEmbeddings('pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sentence(\"To koło mam od kogoś\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"To koło mam od kogoś\" - 5 Tokens]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epl.embed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0].embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 To\n",
      "tensor([ 0.0418, -0.0413, -0.0374, -0.1981,  0.2041,  0.2391, -0.1462, -0.1043,\n",
      "        -0.0191, -0.1028, -0.0799,  0.0986, -0.0434, -0.0448,  0.0196,  0.2728,\n",
      "         0.3163,  0.0610, -0.0049, -0.0601, -0.1671,  0.2504, -0.0872, -0.2340,\n",
      "        -0.2380,  0.1996,  0.0621, -0.1594,  0.0618, -0.1846,  0.0281,  0.0605,\n",
      "         0.0356, -0.1178,  0.0694,  0.0390,  0.0708,  0.1732,  0.1513, -0.1419,\n",
      "         0.1438,  0.2432,  0.0163,  0.0297,  0.1232,  0.1187,  0.0604,  0.1181,\n",
      "         0.0087, -0.1827, -0.0659, -0.2015, -0.2148, -0.0192, -0.0921, -0.0585,\n",
      "        -0.1186, -0.1189,  0.6087,  0.2210, -0.1680, -0.1459, -0.0339, -0.1243,\n",
      "        -0.1485,  0.1045,  0.0243,  0.1766, -0.0404,  0.0435,  0.0607, -0.1181,\n",
      "        -0.2206, -0.2496,  0.1793,  0.0816,  0.0021, -0.1924, -0.0179,  0.0887,\n",
      "        -0.0606, -0.1847,  0.1331,  0.0290, -0.0723,  0.0686,  0.0051,  0.1974,\n",
      "         0.2231,  0.2776, -0.1649,  0.1572, -0.0343,  0.0894,  0.0809,  0.1925,\n",
      "        -0.1422,  0.1927, -0.2488, -0.0462,  0.0748, -0.0164,  0.0356, -0.0378,\n",
      "         0.3490, -0.1227, -0.0968, -0.4830,  0.2315,  0.1790,  0.0666, -0.1279,\n",
      "         0.0418,  0.1632,  0.0945,  0.1919,  0.0942, -0.0804,  0.1034,  0.0011,\n",
      "         0.0155,  0.0102, -0.2518,  0.2612,  0.2350, -0.0061,  0.1298,  0.1479,\n",
      "         0.0670, -0.0483,  0.0526,  0.1127,  0.1246,  0.2493, -0.1565, -0.0652,\n",
      "         0.0195,  0.3671,  0.0468,  0.0610, -0.0129, -0.0360, -0.1191,  0.3289,\n",
      "         0.1167,  0.0454,  0.1141, -0.0972,  0.1716, -0.4088, -0.0837, -0.1658,\n",
      "         0.0406,  0.1955,  0.0955,  0.0524,  0.0738,  0.3493, -0.3761, -0.1841,\n",
      "         0.1606, -0.1787, -0.0647,  0.0907,  0.1389,  0.0743, -0.0368, -0.1236,\n",
      "        -0.1335,  0.0308,  0.0143,  0.0294,  0.1129, -0.1407,  0.0380,  0.2060,\n",
      "         0.1988, -0.2993, -0.1078,  0.1656,  0.0946, -0.2471, -0.0525, -0.0231,\n",
      "        -0.0336,  0.1409,  0.3307, -0.0605,  0.0955, -0.0189, -0.0449, -0.1614,\n",
      "         0.2025,  0.2187, -0.2370,  0.0954, -0.1644, -0.0826,  0.1186,  0.1289,\n",
      "         0.2676, -0.0221,  0.0269,  0.0064,  0.0802,  0.3323, -0.0109, -0.0828,\n",
      "        -0.0636, -0.0215,  0.2679, -0.2085, -0.1679,  0.0948,  0.0204,  0.2340,\n",
      "         0.1767, -0.0317, -0.0307, -0.1869,  0.0258, -0.0509,  0.0124,  0.0067,\n",
      "        -0.1949,  0.2050, -0.0089, -0.0523,  0.1990,  0.0333, -0.1658,  0.0262,\n",
      "         0.0567, -0.4016,  0.0134,  0.1351,  0.1224,  0.1201, -0.1780,  0.0836,\n",
      "        -0.0445, -0.3794,  0.0898,  0.2035,  0.2594, -0.1522,  0.0493, -0.0433,\n",
      "         0.1906,  0.0100, -0.1902, -0.1359, -0.3024, -0.0493,  0.0093,  0.2804,\n",
      "         0.0171, -0.0721, -0.0432,  0.0295,  0.3595,  0.0255,  0.1725, -0.1506,\n",
      "        -0.0234,  0.1065, -0.1221, -0.0065,  0.0587,  0.0474,  0.0862, -0.1299,\n",
      "         0.1986, -0.0488, -0.0545, -0.0778,  0.0951,  0.0325,  0.0066, -0.0387,\n",
      "        -0.0008,  0.0609,  0.0903, -0.2828,  0.1507, -0.1149,  0.0715,  0.0795,\n",
      "        -0.0102, -0.0950, -0.0261,  0.1724,  0.0933,  0.0243, -0.3284, -0.1176,\n",
      "        -0.0081,  0.0920, -0.0170, -0.0376])\n",
      "Token: 2 koło\n",
      "tensor([ 3.1476e-02,  2.1208e-01,  2.2771e-02, -4.8999e-01,  2.5072e-01,\n",
      "         4.0754e-01,  2.5126e-01,  1.0003e-01, -3.4179e-01,  2.4338e-01,\n",
      "        -6.3882e-01,  4.5837e-04,  3.1261e-01, -4.3028e-02, -3.7552e-01,\n",
      "         7.0093e-01,  3.3832e-02, -1.1193e-01,  2.1489e-01, -3.5458e-01,\n",
      "         5.1232e-01,  7.6816e-02, -2.5730e-01, -2.2356e-02, -2.5311e-01,\n",
      "        -1.5355e-01,  3.0361e-01,  4.7513e-01, -1.8770e-01,  6.6787e-02,\n",
      "        -2.4961e-01,  3.6141e-02, -9.5280e-02,  4.0140e-01, -1.6400e-01,\n",
      "         2.1175e-01, -5.4388e-02,  1.8773e-01,  1.9089e-01, -9.2760e-02,\n",
      "         2.6165e-01, -5.5964e-02, -2.7420e-01,  5.2641e-01,  4.3047e-01,\n",
      "        -9.2972e-01,  1.8579e-01,  1.3477e-01, -2.8334e-01,  3.2060e-01,\n",
      "        -2.6863e-01,  1.8125e-02, -3.0625e-01, -7.2453e-02,  2.0095e-01,\n",
      "        -4.4136e-01,  4.4192e-02,  2.3335e-02,  9.7685e-02, -5.0032e-01,\n",
      "         1.1698e-01,  3.3616e-01, -3.5785e-01,  1.9192e-01,  2.0751e-01,\n",
      "         1.2019e-01,  2.9649e-01,  1.6253e-01, -5.6410e-01, -9.9809e-02,\n",
      "        -2.5298e-01, -4.6812e-01, -4.0071e-01,  2.6718e-01,  1.0164e-01,\n",
      "         4.7002e-01,  2.8046e-01, -7.1790e-01, -1.3212e-01, -1.5305e-01,\n",
      "         3.4735e-02, -3.5421e-01,  1.5187e-01, -2.6953e-01,  1.6592e-01,\n",
      "        -6.8956e-02, -3.3043e-01,  8.0371e-02,  5.1978e-02, -2.1838e-01,\n",
      "        -8.1517e-02, -4.1552e-02, -1.0496e-01,  6.2542e-02, -1.9139e-05,\n",
      "        -1.1918e-01, -1.1570e-01,  1.3136e-01,  1.3648e-02, -2.8804e-01,\n",
      "         8.7040e-02, -1.6035e-01,  4.5811e-02, -3.1045e-01, -5.3456e-01,\n",
      "         1.3148e-02, -3.0269e-01, -2.9067e-01,  3.0358e-01, -1.1962e-01,\n",
      "         1.1285e-01, -3.1397e-01,  9.4302e-03, -3.0320e-01, -3.9204e-01,\n",
      "         1.9544e-01, -2.9736e-01, -3.0426e-01, -2.2913e-01,  1.4862e-01,\n",
      "        -2.8506e-02, -2.2239e-01, -3.2349e-01,  5.0160e-01,  1.8569e-01,\n",
      "         6.2241e-02,  1.9807e-01, -5.7170e-01, -9.5040e-02, -2.0835e-02,\n",
      "         6.5421e-01,  2.3685e-01,  1.4581e-01, -2.7480e-01, -1.8842e-01,\n",
      "        -6.0524e-01, -1.3212e-01,  7.2041e-02, -1.2839e-01,  1.6514e-01,\n",
      "         3.7316e-02, -1.3480e-02, -3.9593e-01,  5.2213e-01,  3.0338e-02,\n",
      "        -5.9986e-02, -2.6111e-02, -2.9471e-01,  4.1410e-01, -1.3579e-01,\n",
      "        -2.8783e-01,  2.0587e-01,  5.0390e-02,  2.0275e-01, -2.3077e-02,\n",
      "        -9.6724e-02, -2.0999e-02,  2.8894e-01, -2.2444e-01,  4.7823e-02,\n",
      "         1.2164e-01,  3.0692e-01, -3.3695e-01,  2.3671e-01,  3.6355e-02,\n",
      "        -6.3670e-01,  7.2825e-01,  3.6326e-01, -1.3606e-01,  5.6987e-01,\n",
      "        -1.2048e-01,  7.0706e-01, -2.2588e-01, -1.5789e-01, -2.6368e-01,\n",
      "        -2.9093e-02,  7.5659e-02,  6.2697e-02,  2.8055e-02, -3.5329e-01,\n",
      "         3.8008e-01,  3.1772e-02,  1.5396e-01, -3.8856e-01, -1.8612e-01,\n",
      "         6.8056e-01, -5.8247e-02,  3.6435e-01, -2.7942e-02, -5.4718e-01,\n",
      "         1.7673e-01, -2.7160e-02, -3.4824e-02, -6.5593e-01, -9.4538e-02,\n",
      "        -1.9550e-01, -8.6067e-01, -4.2960e-01, -1.7854e-01,  2.9566e-01,\n",
      "         3.0339e-01, -1.8274e-01, -3.2559e-01, -2.8138e-01, -2.5574e-02,\n",
      "         2.1327e-01,  1.2425e-01,  9.5809e-02, -1.4414e-01,  8.9043e-02,\n",
      "         2.4819e-01,  2.1842e-01, -1.8950e-01, -2.1029e-02, -3.7146e-01,\n",
      "         4.8305e-01,  1.9061e-01, -2.3565e-01, -1.0748e-01, -3.8707e-01,\n",
      "        -6.8641e-02,  2.1669e-01, -3.2448e-01,  5.7893e-02, -2.0331e-01,\n",
      "        -4.8236e-02,  3.3883e-01,  3.2391e-02, -2.4587e-02, -1.7480e-01,\n",
      "        -3.7435e-02,  1.8981e-01,  9.7671e-02, -3.6158e-02,  1.4418e-01,\n",
      "        -4.2320e-02, -9.6415e-02,  1.3315e-01, -1.4597e-03,  1.5262e-01,\n",
      "        -1.5320e-02, -2.9847e-01, -7.5397e-02,  1.1139e-01,  1.3267e-01,\n",
      "         1.8809e-01, -6.0363e-02, -3.3491e-01, -1.0577e-01, -9.4623e-02,\n",
      "         1.7886e-01,  1.6028e-01, -1.8829e-01,  3.9599e-02, -1.0966e-02,\n",
      "        -6.1913e-02,  2.6286e-01,  2.0414e-01, -1.1688e-01,  2.9101e-01,\n",
      "         4.6760e-01,  4.0593e-01,  3.5509e-01, -1.6324e-01,  2.1863e-01,\n",
      "         5.4173e-03, -2.6948e-01,  3.5011e-01, -2.5232e-03, -1.0104e-01,\n",
      "         7.3096e-02, -5.4096e-02, -1.3624e-02, -1.6518e-01, -7.8761e-01,\n",
      "        -1.1385e-01, -1.6120e-01,  1.0840e-01,  2.9193e-01,  1.0319e-01,\n",
      "        -1.7056e-01,  1.9964e-01, -1.0125e-01,  1.3180e-01,  2.1520e-01,\n",
      "         1.3657e-01, -1.5910e-01, -1.6158e-01,  2.0218e-01,  2.7087e-01,\n",
      "        -4.3499e-02, -1.5399e-01,  3.5805e-01,  2.4388e-01,  3.2542e-01,\n",
      "         7.9323e-02, -6.6893e-02,  2.7134e-01,  3.4002e-02, -5.2333e-01])\n",
      "Token: 3 mam\n",
      "tensor([ 2.5108e-01, -1.8648e-01,  2.4728e-01, -4.1299e-01,  7.5337e-02,\n",
      "        -4.0111e-02, -2.9070e-01,  3.9125e-02,  3.6973e-01,  6.8089e-02,\n",
      "        -3.8562e-01,  3.6240e-01, -3.1698e-01,  5.2099e-01,  2.8182e-01,\n",
      "         4.4331e-01,  3.2418e-01,  1.7696e-01, -3.5319e-01,  5.6959e-02,\n",
      "        -2.4546e-01,  8.1925e-02, -3.1416e-01, -2.2715e-01, -1.0532e-01,\n",
      "         3.0697e-01,  2.1778e-01, -2.0357e-01,  1.7920e-01,  2.4478e-01,\n",
      "        -6.1337e-02, -5.7909e-02,  1.5617e-01, -1.4096e-02, -2.0081e-01,\n",
      "         2.3653e-01, -3.3376e-01,  6.2109e-02,  5.3917e-01, -2.6690e-02,\n",
      "         1.3552e-02, -8.0406e-02,  3.9012e-02,  3.5423e-01,  1.9713e-01,\n",
      "        -3.5730e-01, -1.0060e-01,  8.3498e-02,  3.0031e-02, -1.6212e-01,\n",
      "         3.8263e-01,  1.1176e-01,  2.2109e-03,  4.0078e-01, -1.8374e-01,\n",
      "         3.0783e-01,  4.8937e-02,  8.9592e-02,  4.2669e-01,  3.2657e-01,\n",
      "        -2.0581e-01, -2.1436e-01, -7.5350e-02, -2.7511e-01, -1.0375e-01,\n",
      "        -3.2982e-01,  1.4777e-01,  4.0744e-01, -1.6586e-01,  5.7122e-01,\n",
      "        -4.2576e-02, -2.1489e-01,  7.7746e-02, -3.8267e-01,  4.4412e-01,\n",
      "         2.5244e-01, -3.3755e-01, -1.9344e-01, -2.5234e-01, -2.5745e-01,\n",
      "        -1.1111e-01, -2.4205e-01, -8.3163e-02, -7.7350e-02,  3.8059e-02,\n",
      "         1.6800e-01,  2.1917e-01,  6.4545e-02,  4.4589e-01,  2.5459e-01,\n",
      "        -4.8161e-01,  2.8344e-02, -5.3273e-01,  3.2841e-02, -1.6033e-02,\n",
      "        -1.6253e-01, -2.1460e-01,  1.9052e-01, -1.6873e-01, -2.4025e-01,\n",
      "         4.1180e-01, -2.1537e-01, -3.5761e-01, -1.9801e-01,  1.2960e-02,\n",
      "        -1.1711e-02, -5.6045e-01, -5.8538e-01,  3.6588e-01,  1.1876e-01,\n",
      "         3.8866e-01, -3.9366e-02, -9.3167e-02, -1.0375e-01,  4.2804e-01,\n",
      "         2.5110e-01, -3.3462e-01, -1.4681e-02,  3.2390e-01, -1.3894e-01,\n",
      "         3.4935e-01,  2.8474e-01, -1.9578e-01, -2.9939e-04,  4.3916e-01,\n",
      "         1.9100e-01,  2.7203e-02,  2.3776e-02,  5.6055e-01, -1.2940e-01,\n",
      "         8.8139e-02,  2.0299e-01,  6.3614e-01,  1.6043e-01, -1.7215e-01,\n",
      "        -1.5040e-01,  1.6310e-01,  3.9664e-02,  4.5635e-01,  1.3795e-01,\n",
      "         2.1283e-01,  7.4790e-02,  3.0917e-01,  3.4825e-01, -2.6528e-01,\n",
      "         2.5780e-01, -7.9553e-02,  4.9868e-02, -1.2643e-02, -5.3817e-02,\n",
      "        -2.5407e-02, -2.2485e-01,  1.8670e-01, -9.7749e-03,  8.8340e-02,\n",
      "        -5.8211e-01, -1.1816e-01,  7.1974e-02, -4.3705e-01, -2.4452e-01,\n",
      "        -3.4285e-01, -1.9320e-01, -5.3305e-01,  9.1246e-02, -1.7991e-01,\n",
      "         1.0155e-01, -1.4915e-01,  1.0373e-01, -2.1669e-01,  2.7267e-01,\n",
      "         2.7416e-01, -1.0611e-04, -2.7349e-01, -1.7750e-01,  3.3904e-01,\n",
      "        -6.3174e-02,  2.0631e-01, -4.0511e-02, -2.3415e-01, -1.4295e-01,\n",
      "         3.5130e-01, -5.3312e-01,  3.5116e-01,  2.9518e-02,  1.3276e-01,\n",
      "         3.3985e-02,  2.7578e-01,  1.4982e-01, -1.2872e-01,  2.3907e-02,\n",
      "         2.8079e-01, -2.1865e-01, -2.6321e-02,  4.3827e-01, -4.0182e-01,\n",
      "         9.2137e-02, -1.0473e-01,  2.6859e-01,  1.2033e-01,  1.2041e-01,\n",
      "        -9.8940e-02,  1.4374e-01,  1.4166e-01, -2.3504e-01, -2.2352e-01,\n",
      "         2.3635e-01, -1.4277e-02, -2.3245e-03,  2.8185e-01, -1.2513e-02,\n",
      "         2.4930e-02, -1.0623e-01,  6.5926e-03,  3.6241e-01, -2.4536e-01,\n",
      "        -5.5415e-02,  1.8789e-01, -2.5714e-01,  1.5054e-02, -1.6286e-01,\n",
      "         2.5515e-02,  1.0079e-01, -5.3938e-01, -7.4605e-02,  1.7101e-01,\n",
      "         4.1442e-01,  2.2209e-01, -9.3075e-02,  5.8261e-01,  6.0005e-02,\n",
      "        -1.0055e-01,  1.8943e-01, -3.6734e-01, -1.8010e-01, -2.3076e-01,\n",
      "        -7.6142e-02,  2.3047e-01,  3.7862e-01, -1.0728e-01,  8.1964e-02,\n",
      "        -1.3024e-01, -1.3276e-02, -8.4699e-02,  2.0782e-01,  2.5363e-01,\n",
      "        -2.9827e-01, -8.2721e-02,  3.4771e-01,  3.6822e-01,  1.5177e-01,\n",
      "        -3.6573e-01,  1.9791e-01, -5.9958e-01, -5.9737e-02, -1.5041e-02,\n",
      "         4.5657e-02,  2.1123e-01, -1.8397e-01,  2.0775e-01, -5.3766e-01,\n",
      "         3.2403e-01,  4.1428e-02,  3.8982e-01, -8.0539e-02, -1.1120e-01,\n",
      "        -2.7063e-01,  2.9162e-02,  3.1471e-02, -3.4037e-01,  2.3601e-01,\n",
      "         4.5669e-01, -1.0775e-01,  3.5128e-01,  2.2546e-01, -9.2026e-02,\n",
      "         3.2555e-01,  2.0414e-01,  3.0759e-01, -1.6880e-01, -1.6826e-01,\n",
      "         3.8635e-01, -2.1700e-01, -3.7841e-02, -4.4549e-01,  1.3896e-01,\n",
      "         1.2604e-02, -7.8528e-02,  9.6899e-02,  3.0406e-01, -4.1566e-01,\n",
      "         2.9900e-01,  3.2443e-01,  2.3162e-02,  5.5487e-02, -1.7217e-01,\n",
      "        -3.3025e-01, -2.1549e-01, -1.6014e-01, -1.7413e-01,  2.8461e-02])\n",
      "Token: 4 od\n",
      "tensor([ 2.6015e-01, -9.7763e-02, -1.2625e-01, -5.3770e-01, -5.5727e-02,\n",
      "         1.3900e-01,  3.3295e-01,  2.9604e-01, -5.1816e-02, -8.8744e-02,\n",
      "         1.7724e-01,  1.6233e-01,  8.5730e-02,  2.0162e-01, -8.9568e-02,\n",
      "         5.0043e-01,  2.5782e-01, -1.7896e-01, -1.2937e-01,  2.1579e-01,\n",
      "        -1.8966e-01, -2.5613e-02,  2.4496e-01, -6.8184e-02,  3.7980e-02,\n",
      "         7.3335e-02,  7.8848e-02, -2.7883e-02, -1.6962e-01, -1.7039e-01,\n",
      "        -1.2056e-01,  1.3520e-01,  5.2019e-02,  1.0858e-01, -4.2732e-01,\n",
      "         1.3977e-01, -1.8912e-01,  3.8253e-02,  9.9348e-02,  2.2668e-01,\n",
      "        -2.2842e-01,  1.2474e-02, -3.6920e-01,  2.8431e-01,  3.5969e-02,\n",
      "        -3.5080e-01, -3.0816e-01, -1.4703e-01, -3.2550e-05,  1.3620e-01,\n",
      "        -2.8790e-02, -2.0382e-01,  9.4106e-02,  1.3053e-01, -9.7131e-03,\n",
      "        -6.2077e-03, -2.6529e-01, -4.9906e-02,  2.3243e-01, -2.2959e-01,\n",
      "         2.1716e-02, -8.0913e-02,  9.7983e-02, -1.2405e-01, -3.6332e-02,\n",
      "         2.9517e-01, -8.0150e-02,  6.0085e-02, -1.8934e-01, -2.2392e-01,\n",
      "        -1.6720e-01, -1.8409e-01, -4.3474e-01,  1.3686e-02, -2.0493e-01,\n",
      "         1.8084e-01,  1.1816e-01, -4.7534e-01,  5.3944e-02,  1.4745e-01,\n",
      "        -4.4995e-01, -1.0110e-01,  1.0457e-01,  4.2637e-02, -1.4655e-01,\n",
      "        -1.1659e-01, -7.0247e-02,  3.4766e-01,  2.2883e-01, -7.8308e-02,\n",
      "         1.9298e-01,  3.1025e-01, -1.7499e-01, -2.3407e-02,  2.8188e-01,\n",
      "        -1.0590e-01, -1.1005e-01,  1.8935e-02, -2.1728e-01, -1.3968e-01,\n",
      "        -1.8700e-01, -7.2764e-02,  2.8394e-01,  3.7550e-01,  5.0600e-03,\n",
      "        -5.2322e-02, -8.4374e-02,  2.8477e-02,  1.3336e-01,  1.6449e-02,\n",
      "         1.1105e-01, -1.1282e-01,  2.6505e-01, -1.4715e-01, -1.5296e-01,\n",
      "         2.4900e-01,  1.8432e-01,  9.6045e-02, -1.7319e-01, -1.0406e-01,\n",
      "         1.9396e-02,  1.0313e-01, -4.0760e-02, -1.6570e-01,  1.7139e-01,\n",
      "        -4.5877e-02,  6.1746e-02, -4.3219e-01, -1.0728e-01, -2.7244e-01,\n",
      "         1.9018e-01,  2.3721e-01,  1.8928e-01, -1.5524e-01, -1.6389e-02,\n",
      "        -1.6742e-01, -7.2675e-03,  1.8657e-02, -1.3632e-01,  1.1340e-01,\n",
      "         1.4074e-01, -1.8782e-01, -5.0368e-02,  1.5155e-02,  2.2413e-01,\n",
      "         4.5686e-01, -4.9628e-02, -2.8008e-01,  2.1659e-01, -1.1691e-01,\n",
      "        -1.5138e-01,  1.0054e-01, -1.7438e-01,  4.8992e-01,  9.7409e-02,\n",
      "        -4.8939e-01, -3.1944e-01,  5.9447e-02,  2.8167e-01, -1.3357e-01,\n",
      "         1.0574e-01, -3.8607e-01,  6.2614e-02,  1.3681e-01, -9.8522e-02,\n",
      "        -2.1960e-02,  2.2819e-01, -4.9803e-02, -6.3896e-02, -3.0066e-01,\n",
      "         1.0481e-01,  1.8454e-01, -2.2436e-01,  2.4566e-02, -4.4702e-01,\n",
      "        -1.6521e-01, -1.2514e-01, -3.4048e-03,  7.8892e-03,  3.0343e-01,\n",
      "         1.4691e-03, -1.2624e-01,  4.7054e-01,  7.6677e-02, -1.2517e-02,\n",
      "         1.0278e-01,  1.5416e-01,  3.4434e-01, -1.0487e-01,  5.9536e-02,\n",
      "         2.2914e-01, -7.4350e-02,  1.6399e-01,  1.1010e-01, -2.7352e-01,\n",
      "         1.1558e-01,  1.9440e-01, -2.4201e-01, -7.6621e-02,  7.3430e-03,\n",
      "         2.1223e-01, -5.5558e-02,  1.2493e-04, -1.9660e-01,  2.2194e-02,\n",
      "        -2.7073e-01,  4.7438e-02,  5.8990e-02, -2.7060e-01, -1.2071e-01,\n",
      "         4.3045e-03, -1.5637e-01, -3.1690e-01,  4.0331e-02, -2.2207e-01,\n",
      "         1.7713e-01, -3.1668e-03, -1.5630e-01,  1.9415e-01, -3.5020e-01,\n",
      "         1.3061e-01, -4.5755e-02, -1.6738e-01,  9.3808e-02,  1.6122e-01,\n",
      "         3.7693e-01,  6.6994e-02, -2.4951e-01,  7.5295e-02, -9.1504e-02,\n",
      "         1.3694e-01,  1.8539e-01,  1.1942e-01, -1.5802e-01, -1.3691e-01,\n",
      "         1.8439e-01, -1.4172e-01, -1.0413e-03, -4.4414e-02,  2.5605e-01,\n",
      "         2.6027e-01, -7.3313e-02,  2.0846e-01, -2.5761e-02,  1.8235e-01,\n",
      "         5.3220e-02, -7.4242e-02, -2.2803e-01,  2.6399e-01,  9.9741e-02,\n",
      "        -2.2509e-01,  2.4486e-02, -1.9245e-01, -1.7101e-01, -2.1065e-01,\n",
      "         2.1162e-01, -2.8716e-01,  5.3621e-02, -2.5142e-01,  1.9592e-01,\n",
      "        -1.0264e-01,  1.9232e-02,  3.3777e-01, -1.6338e-01,  1.2625e-01,\n",
      "         1.6610e-01, -4.0606e-01, -9.9649e-02, -7.0234e-02, -1.7737e-01,\n",
      "         8.0335e-02,  5.8240e-02,  2.3641e-01,  1.0563e-01, -9.4792e-02,\n",
      "         2.7525e-01,  1.7708e-01,  2.7482e-01,  1.6896e-01,  3.0639e-01,\n",
      "        -1.3099e-01,  5.2332e-02, -1.3868e-01,  1.0458e-01, -1.0660e-01,\n",
      "         3.0066e-01, -1.7989e-02, -1.1196e-01, -1.7393e-01, -1.4002e-01,\n",
      "         2.6920e-01,  1.2751e-01, -6.3953e-02, -1.3772e-01, -1.6069e-01,\n",
      "        -2.2446e-01,  1.9344e-02, -3.1133e-01, -2.3715e-01, -1.6868e-03])\n",
      "Token: 5 kogoś\n",
      "tensor([-0.0919, -0.0111,  0.0371, -0.3636,  0.0921,  0.3147, -0.1493, -0.1932,\n",
      "         0.3521,  0.1429, -0.3298,  0.2281, -0.1819, -0.2854,  0.1723,  0.3510,\n",
      "         0.6198, -0.2545, -0.3690,  0.5951, -0.5412,  0.5674,  0.1900, -0.4073,\n",
      "        -0.2190,  0.1601,  0.1281, -0.3013,  0.1545,  0.0886,  0.0859, -0.1993,\n",
      "         0.4090, -0.2139,  0.2442,  0.4317, -0.1170,  0.3013,  0.2676,  0.0174,\n",
      "        -0.3512,  0.0938,  0.0671,  0.2328,  0.1856, -0.3429,  0.3810, -0.0413,\n",
      "        -0.2145, -0.0289,  0.2476, -0.0543, -0.2056,  0.0961,  0.1294, -0.2626,\n",
      "        -0.0698, -0.3449,  0.5070,  0.1107,  0.2561, -0.5093, -0.1240,  0.4094,\n",
      "         0.0876, -0.0632, -0.2513,  0.4120, -0.3563,  0.0556,  0.0894,  0.1422,\n",
      "         0.2873,  0.0580,  0.7479,  0.1967, -0.2769, -0.3857,  0.0024, -0.2371,\n",
      "        -0.1134, -0.2820,  0.0068,  0.0517, -0.4823,  0.0238,  0.0309, -0.1187,\n",
      "         0.4916,  0.3618, -0.5797,  0.1173,  0.0336, -0.5149, -0.2839, -0.0048,\n",
      "         0.0128, -0.1795, -0.2334, -0.0411, -0.2099, -0.2773, -0.0548,  0.1452,\n",
      "        -0.1798, -0.1692, -0.1420, -0.3522,  0.2198,  0.4636,  0.3307, -0.1815,\n",
      "         0.2122, -0.1564, -0.2118,  0.3065,  0.1723, -0.0687,  0.0258,  0.0012,\n",
      "         0.1267,  0.0870, -0.0020,  0.1031,  0.2194, -0.0740, -0.0747,  0.1319,\n",
      "         0.2481,  0.0053, -0.3070,  0.1891,  0.4153,  0.0052, -0.0492,  0.0042,\n",
      "         0.0212,  0.0116,  0.2202,  0.4280,  0.2299,  0.0795, -0.0498,  0.2509,\n",
      "        -0.1555,  0.6405, -0.2853, -0.2557,  0.1530, -0.4136,  0.0803, -0.3789,\n",
      "         0.0491,  0.2213, -0.0524, -0.6004, -0.2216,  0.5205, -0.1284,  0.0607,\n",
      "        -0.3299, -0.2665,  0.0940, -0.0331, -0.0328, -0.0160, -0.3542, -0.0107,\n",
      "        -0.1785,  0.1717, -0.2207,  0.0410, -0.2175, -0.2123, -0.0169,  0.0645,\n",
      "        -0.2923,  0.0753, -0.2630, -0.0066,  0.1469, -0.0580, -0.0192,  0.0812,\n",
      "         0.1526,  0.2675,  0.1401,  0.0304, -0.0085,  0.1976,  0.1617,  0.0262,\n",
      "         0.1895,  0.2648, -0.0203,  0.1061, -0.0354, -0.1207, -0.1495,  0.3080,\n",
      "        -0.2356, -0.1730,  0.2810, -0.0707, -0.4280,  0.2693,  0.0540,  0.2247,\n",
      "        -0.1217,  0.1837,  0.1791,  0.2069, -0.2166,  0.2161,  0.4667, -0.0200,\n",
      "         0.5818, -0.1537,  0.2100, -0.1356, -0.0403, -0.1892, -0.0886,  0.2851,\n",
      "         0.0296,  0.2984,  0.0471, -0.2076,  0.0194, -0.3599, -0.0800, -0.2685,\n",
      "        -0.1050, -0.3448, -0.0965,  0.0464, -0.1988,  0.1527,  0.0141, -0.2062,\n",
      "        -0.1538,  0.0789, -0.0311,  0.2682,  0.2568, -0.4245,  0.0068, -0.0514,\n",
      "         0.2719,  0.1749, -0.0369,  0.2651, -0.6647, -0.1858, -0.0686,  0.3042,\n",
      "        -0.0486, -0.1094,  0.2207, -0.1755,  0.3615, -0.0832, -0.0333,  0.0841,\n",
      "        -0.0536, -0.2203,  0.3295,  0.1143, -0.0612,  0.3237,  0.2409, -0.4774,\n",
      "         0.1201,  0.1972, -0.1492,  0.2171,  0.2072,  0.1610, -0.1385, -0.4101,\n",
      "         0.0616, -0.3899, -0.0188, -0.2788, -0.0643, -0.1243,  0.1304,  0.1835,\n",
      "         0.1940, -0.1421, -0.0329,  0.3120,  0.0732,  0.2599, -0.2686, -0.0038,\n",
      "        -0.0970, -0.1476,  0.2795,  0.1664])\n"
     ]
    }
   ],
   "source": [
    "for token in s:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"LingFeatured NLI_PL_20.03.2020.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = np.array([x[:-5] for x in data['verb'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clean:\n",
    "    s = Sentence(c)\n",
    "    epl.embed(s)\n",
    "    embeddings.append(torch.cat([w.embedding.view(1, w.embedding.shape[0]) for w in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), array([224, 111,  25,   7], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([e.shape[0] for e in embeddings ], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB = torch.cat([F.pad(embeddings[i], (0,0,4-embeddings[i].shape[0],0)).view(1,4,300) for i in range(len(embeddings))], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(300, 5, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = embeddings[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = e.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out, hidden= lstm(EMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([367, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(hidden,2)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model LSTM-end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMend2end(nn.Module):\n",
    "    def __init__(self, LSTM_hidden, output_size):\n",
    "        super(LSTMend2end, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(300, LSTM_hidden, batch_first=True)\n",
    "        self.L1 = nn.Linear(2*LSTM_hidden, 2*LSTM_hidden)\n",
    "        self.L2 = nn.Linear(2*LSTM_hidden, LSTM_hidden)\n",
    "        self.L3 = nn.Linear(LSTM_hidden, output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward implementation for batch training.\n",
    "        Params:\n",
    "            - X: Batch\n",
    "        \n",
    "        Output:\n",
    "            - Y: shape: n-obs, output_size\n",
    "            \n",
    "        forward(seq) = seq -> lstm -> linear -> relu -> linear -> relu -> linear -> sigmoid\n",
    "        \"\"\"\n",
    "        _, hidden = self.lstm(X)\n",
    "        X = torch.cat(hidden, 2)[0]\n",
    "        X = torch.relu(self.L1(X))\n",
    "        X = torch.relu(self.L2(X))\n",
    "        X = torch.sigmoid(self.L3(X))\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, y_pred):\n",
    "    d = y - y_pred\n",
    "    return d.T @ d / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LSTMend2end(300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4900, 0.5114, 0.5114],\n",
       "        [0.4892, 0.5103, 0.5130],\n",
       "        [0.4903, 0.5113, 0.5121],\n",
       "        ...,\n",
       "        [0.4902, 0.5103, 0.5116],\n",
       "        [0.4918, 0.5113, 0.5115],\n",
       "        [0.4907, 0.5116, 0.5107]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.forward(EMB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model LSTM-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distance matrix\n",
    "\"\"\"\n",
    "def dist(M):\n",
    "    W = M @ M.T\n",
    "    D = torch.diag(W).reshape(M.shape[0],1)\n",
    "    return D + D.T - 2*W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kernel Function\n",
    "\n",
    "K()\n",
    "\"\"\"\n",
    "def K(M, gamma=.5):\n",
    "    D = dist(M)\n",
    "    return torch.exp(-gamma * D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM_SVM Model\n",
    "\n",
    "It is a LSTM model with radial basis function kernel SVM on top (trained at once).\n",
    "\n",
    "Forward(seq) = seq -> lstm -> K -> ouput \n",
    "\n",
    "\"\"\"\n",
    "class LSTM_SVM(nn.Module):\n",
    "    def __init__(self, LSTM_hidden, data_size, output_size, gamma=1):\n",
    "        super(LSTM_SVM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(300, LSTM_hidden, batch_first=True)\n",
    "        self.L1 = nn.Linear(data_size, output_size)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward implementation for batch training.\n",
    "        Params:\n",
    "            - X: Batch\n",
    "        \n",
    "        Output:\n",
    "            - Y: shape: n-obs, output_size\n",
    "            \n",
    "        forward(seq) = Forward(seq) = seq -> lstm -> K -> ouput \n",
    "        \"\"\"\n",
    "        _, hidden = self.lstm(X)\n",
    "        X = torch.cat(hidden, 2)[0]\n",
    "        X = K(X, self.gamma)\n",
    "        X = self.L1(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_L(y, y_pred):\n",
    "    return torch.sum(torch.clamp(y_pred[y] + 1, min=0)) + torch.sum(torch.clamp(-y_pred[~y] + 1, min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LSTM_SVM(300, 367, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1154.3909, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_L(l.forward(EMB) > 0, l.forward(EMB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
